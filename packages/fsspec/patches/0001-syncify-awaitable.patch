diff --git a/fsspec/asyn.py b/fsspec/asyn.py
index fb4e05e..45b060e 100644
--- a/fsspec/asyn.py
+++ b/fsspec/asyn.py
@@ -18,7 +18,7 @@ from .spec import AbstractBufferedFile, AbstractFileSystem
 from .utils import glob_translate, is_exception, other_paths
 
 private = re.compile("_[^_]")
-iothread = [None]  # dedicated fsspec IO thread
+# iothread = [None]  # dedicated fsspec IO thread
 loop = [None]  # global event loop for any non-async instance
 _lock = None  # global lock placeholder
 get_running_loop = asyncio.get_running_loop
@@ -43,7 +43,7 @@ def reset_lock():
     """
     global _lock
 
-    iothread[0] = None
+    # iothread[0] = None
     loop[0] = None
     _lock = None
 
@@ -69,40 +69,54 @@ def sync(loop, func, *args, timeout=None, **kwargs):
     >>> fsspec.asyn.sync(fsspec.asyn.get_loop(), func, *args,
                          timeout=timeout, **kwargs)
     """
-    timeout = timeout if timeout else None  # convert 0 or 0.0 to None
-    # NB: if the loop is not running *yet*, it is OK to submit work
-    # and we will wait for it
-    if loop is None or loop.is_closed():
-        raise RuntimeError("Loop is not running")
-    try:
-        loop0 = asyncio.events.get_running_loop()
-        if loop0 is loop:
-            raise NotImplementedError("Calling sync() from within a running loop")
-    except NotImplementedError:
-        raise
-    except RuntimeError:
-        pass
+
     coro = func(*args, **kwargs)
-    result = [None]
-    event = threading.Event()
-    asyncio.run_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)
-    while True:
-        # this loops allows thread to get interrupted
-        if event.wait(1):
-            break
-        if timeout is not None:
-            timeout -= 1
-            if timeout < 0:
-                raise FSTimeoutError
-
-    return_result = result[0]
-    if isinstance(return_result, asyncio.TimeoutError):
-        # suppress asyncio.TimeoutError, raise FSTimeoutError
-        raise FSTimeoutError from return_result
-    elif isinstance(return_result, BaseException):
-        raise return_result
+    awaitable = coro.__await__()
+
+    try:
+        next(awaitable)
+    except StopIteration as result:
+        return result.value
+    except Exception as err:
+        raise err
     else:
-        return return_result
+        raise RuntimeError("could not syncify an awaitable")
+
+
+    # timeout = timeout if timeout else None  # convert 0 or 0.0 to None
+    # # NB: if the loop is not running *yet*, it is OK to submit work
+    # # and we will wait for it
+    # if loop is None or loop.is_closed():
+    #     raise RuntimeError("Loop is not running")
+    # try:
+    #     loop0 = asyncio.events.get_running_loop()
+    #     if loop0 is loop:
+    #         raise NotImplementedError("Calling sync() from within a running loop")
+    # except NotImplementedError:
+    #     raise
+    # except RuntimeError:
+    #     pass
+    # coro = func(*args, **kwargs)
+    # result = [None]
+    # event = threading.Event()
+    # asyncio.run_coroutine_threadsafe(_runner(event, coro, result, timeout), loop)
+    # while True:
+    #     # this loops allows thread to get interrupted
+    #     if event.wait(1):
+    #         break
+    #     if timeout is not None:
+    #         timeout -= 1
+    #         if timeout < 0:
+    #             raise FSTimeoutError
+
+    # return_result = result[0]
+    # if isinstance(return_result, asyncio.TimeoutError):
+    #     # suppress asyncio.TimeoutError, raise FSTimeoutError
+    #     raise FSTimeoutError from return_result
+    # elif isinstance(return_result, BaseException):
+    #     raise return_result
+    # else:
+    #     return return_result
 
 
 def sync_wrapper(func, obj=None):
@@ -144,10 +158,10 @@ def get_loop():
             if loop[0] is None:
                 with _selector_policy():
                     loop[0] = asyncio.new_event_loop()
-                th = threading.Thread(target=loop[0].run_forever, name="fsspecIO")
-                th.daemon = True
-                th.start()
-                iothread[0] = th
+                # th = threading.Thread(target=loop[0].run_forever, name="fsspecIO")
+                # th.daemon = True
+                # th.start()
+                # iothread[0] = th
     return loop[0]
 
 
@@ -232,28 +246,30 @@ async def _run_coros_in_chunks(
         If yes, you normally expect smaller batches.
     """
 
-    if batch_size is None:
-        batch_size = _get_batch_size(nofiles=nofiles)
-
-    if batch_size == -1:
-        batch_size = len(coros)
-
-    assert batch_size > 0
-    results = []
-    for start in range(0, len(coros), batch_size):
-        chunk = [
-            asyncio.Task(asyncio.wait_for(c, timeout=timeout))
-            for c in coros[start : start + batch_size]
-        ]
-        if callback is not DEFAULT_CALLBACK:
-            [
-                t.add_done_callback(lambda *_, **__: callback.relative_update(1))
-                for t in chunk
-            ]
-        results.extend(
-            await asyncio.gather(*chunk, return_exceptions=return_exceptions),
-        )
-    return results
+    return [await c for c in coros]
+
+    # if batch_size is None:
+    #     batch_size = _get_batch_size(nofiles=nofiles)
+
+    # if batch_size == -1:
+    #     batch_size = len(coros)
+
+    # assert batch_size > 0
+    # results = []
+    # for start in range(0, len(coros), batch_size):
+    #     chunk = [
+    #         asyncio.Task(asyncio.wait_for(c, timeout=timeout))
+    #         for c in coros[start : start + batch_size]
+    #     ]
+    #     if callback is not DEFAULT_CALLBACK:
+    #         [
+    #             t.add_done_callback(lambda *_, **__: callback.relative_update(1))
+    #             for t in chunk
+    #         ]
+    #     results.extend(
+    #         await asyncio.gather(*chunk, return_exceptions=return_exceptions),
+    #     )
+    # return results
 
 
 # these methods should be implemented as async by any async-able backend
